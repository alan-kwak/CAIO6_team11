{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kospi Prediction using transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset \n",
    "\n",
    "import tqdm\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>S&amp;P</th>\n",
       "      <th>currency</th>\n",
       "      <th>gold</th>\n",
       "      <th>kospi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5317</th>\n",
       "      <td>2024-04-17</td>\n",
       "      <td>5022.209961</td>\n",
       "      <td>1387.339966</td>\n",
       "      <td>2371.699951</td>\n",
       "      <td>2584.179932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5318</th>\n",
       "      <td>2024-04-18</td>\n",
       "      <td>5011.120117</td>\n",
       "      <td>1379.540039</td>\n",
       "      <td>2382.300049</td>\n",
       "      <td>2634.699951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5319</th>\n",
       "      <td>2024-04-19</td>\n",
       "      <td>4967.229980</td>\n",
       "      <td>1379.400024</td>\n",
       "      <td>2398.399902</td>\n",
       "      <td>2591.860107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5320</th>\n",
       "      <td>2024-04-22</td>\n",
       "      <td>5010.600098</td>\n",
       "      <td>1373.930054</td>\n",
       "      <td>2347.000000</td>\n",
       "      <td>2591.860107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5321</th>\n",
       "      <td>2024-04-23</td>\n",
       "      <td>5010.600098</td>\n",
       "      <td>1373.930054</td>\n",
       "      <td>2347.000000</td>\n",
       "      <td>2634.830078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date          S&P     currency         gold        kospi\n",
       "5317  2024-04-17  5022.209961  1387.339966  2371.699951  2584.179932\n",
       "5318  2024-04-18  5011.120117  1379.540039  2382.300049  2634.699951\n",
       "5319  2024-04-19  4967.229980  1379.400024  2398.399902  2591.860107\n",
       "5320  2024-04-22  5010.600098  1373.930054  2347.000000  2591.860107\n",
       "5321  2024-04-23  5010.600098  1373.930054  2347.000000  2634.830078"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./total.csv')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['S&P', 'currency', 'gold', 'kospi'], dtype=object)"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = df.columns[1:].values\n",
    "col_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables and hyperparameter\n",
    "IN_DIM = 64\n",
    "DAY_INT = 1\n",
    "BATCH_SIZE = 64\n",
    "SCALER = 'MINMAX'   # 'NORMAL'\n",
    "# SCALER = 'NORMAL'   # 'NORMAL'\n",
    "TRAIN_TEST_SPLIT = 0.9\n",
    "LR = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S&amp;P</th>\n",
       "      <th>currency</th>\n",
       "      <th>gold</th>\n",
       "      <th>kospi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1944.588598</td>\n",
       "      <td>1109.020207</td>\n",
       "      <td>1175.492837</td>\n",
       "      <td>1876.226251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var</th>\n",
       "      <td>864381.983793</td>\n",
       "      <td>9350.660785</td>\n",
       "      <td>184854.497651</td>\n",
       "      <td>283255.535559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4796.560059</td>\n",
       "      <td>1571.400024</td>\n",
       "      <td>2051.500000</td>\n",
       "      <td>3305.209961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>676.530029</td>\n",
       "      <td>886.679993</td>\n",
       "      <td>374.799988</td>\n",
       "      <td>719.590027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                S&P     currency           gold          kospi\n",
       "mean    1944.588598  1109.020207    1175.492837    1876.226251\n",
       "var   864381.983793  9350.660785  184854.497651  283255.535559\n",
       "max     4796.560059  1571.400024    2051.500000    3305.209961\n",
       "min      676.530029   886.679993     374.799988     719.590027"
      ]
     },
     "execution_count": 657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df.iloc[:int(len(df) * TRAIN_TEST_SPLIT), :].drop('Date', axis=1)\n",
    "df_test = df.iloc[int(len(df) * TRAIN_TEST_SPLIT): , :].drop('Date', axis=1)\n",
    "# print(df_train.tail())\n",
    "# print(df_test.head())\n",
    "scale_params = pd.DataFrame(index=['mean', 'var', 'max', 'min'])\n",
    "for i in col_names:\n",
    "    scale_params[i] = [df_train[i].mean(), df_train[i].var(), df_train[i].max(), df_train[i].min()]\n",
    "scale_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S&amp;P</th>\n",
       "      <th>currency</th>\n",
       "      <th>gold</th>\n",
       "      <th>kospi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4784</th>\n",
       "      <td>4545.859863</td>\n",
       "      <td>1214.500000</td>\n",
       "      <td>1919.099976</td>\n",
       "      <td>2739.850098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4785</th>\n",
       "      <td>4582.640137</td>\n",
       "      <td>1218.780029</td>\n",
       "      <td>1929.199951</td>\n",
       "      <td>2757.899902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4786</th>\n",
       "      <td>4525.120117</td>\n",
       "      <td>1213.900024</td>\n",
       "      <td>1922.900024</td>\n",
       "      <td>2759.199951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4787</th>\n",
       "      <td>4481.149902</td>\n",
       "      <td>1218.750000</td>\n",
       "      <td>1918.400024</td>\n",
       "      <td>2735.030029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4788</th>\n",
       "      <td>4500.209961</td>\n",
       "      <td>1217.599976</td>\n",
       "      <td>1933.800049</td>\n",
       "      <td>2695.860107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              S&P     currency         gold        kospi\n",
       "4784  4545.859863  1214.500000  1919.099976  2739.850098\n",
       "4785  4582.640137  1218.780029  1929.199951  2757.899902\n",
       "4786  4525.120117  1213.900024  1922.900024  2759.199951\n",
       "4787  4481.149902  1218.750000  1918.400024  2735.030029\n",
       "4788  4500.209961  1217.599976  1933.800049  2695.860107"
      ]
     },
     "execution_count": 658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S&amp;P</th>\n",
       "      <th>currency</th>\n",
       "      <th>gold</th>\n",
       "      <th>kospi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5317</th>\n",
       "      <td>1.054769</td>\n",
       "      <td>0.731189</td>\n",
       "      <td>1.190970</td>\n",
       "      <td>0.721138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5318</th>\n",
       "      <td>1.052077</td>\n",
       "      <td>0.719798</td>\n",
       "      <td>1.197292</td>\n",
       "      <td>0.740677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5319</th>\n",
       "      <td>1.041424</td>\n",
       "      <td>0.719593</td>\n",
       "      <td>1.206894</td>\n",
       "      <td>0.724109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5320</th>\n",
       "      <td>1.051951</td>\n",
       "      <td>0.711605</td>\n",
       "      <td>1.176239</td>\n",
       "      <td>0.724109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5321</th>\n",
       "      <td>1.051951</td>\n",
       "      <td>0.711605</td>\n",
       "      <td>1.176239</td>\n",
       "      <td>0.740728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           S&P  currency      gold     kospi\n",
       "5317  1.054769  0.731189  1.190970  0.721138\n",
       "5318  1.052077  0.719798  1.197292  0.740677\n",
       "5319  1.041424  0.719593  1.206894  0.724109\n",
       "5320  1.051951  0.711605  1.176239  0.724109\n",
       "5321  1.051951  0.711605  1.176239  0.740728"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.DataFrame()\n",
    "test_data = pd.DataFrame()\n",
    "if SCALER == 'MINMAX':\n",
    "    for i in col_names:\n",
    "        train_data[i] = df_train[i].apply(lambda x: (x - scale_params.loc['min', i])/(scale_params.loc['max', i] - scale_params.loc['min', i]))\n",
    "        test_data[i] = df_test[i].apply(lambda x: (x - scale_params.loc['min', i])/(scale_params.loc['max', i] - scale_params.loc['min', i]))\n",
    "elif SCALER == 'NORMAL':\n",
    "    for i in col_names:\n",
    "        train_data[i] = df_train[i].apply(lambda x: (x - scale_params.loc['mean', i])/scale_params.loc['var', i])\n",
    "        test_data[i] = df_test[i].apply(lambda x: (x - scale_params.loc['mean', i])/scale_params.loc['var', i])\n",
    "test_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stockdataset(Dataset):\n",
    "    def __init__(self, data, input_size=128, day_interval=2):\n",
    "        self.data = data\n",
    "        self.len = len(data)\n",
    "        start_pos = (self.len - input_size -1) % day_interval\n",
    "        iter_times = (self.len - input_size -1) // day_interval + 1\n",
    "        print(self.len, start_pos, iter_times)\n",
    "        X = []\n",
    "        Y = []\n",
    "        for i in range(iter_times):  # check iteration number \n",
    "            start = start_pos + i * day_interval\n",
    "            end = start + input_size    # -1 if use loc\n",
    "            x_num = data.iloc[start:end, :].to_numpy()\n",
    "            # x_num = x_num.astype(float)\n",
    "            X.append(x_num.T)\n",
    "            Y.append(df.loc[end + 1, 'kospi'])\n",
    "        self.x = X\n",
    "        self.y = Y\n",
    "        self.len = len(X)\n",
    "        print(start, end)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4789 0 4724\n",
      "4724 4788\n",
      "533 0 468\n",
      "468 532\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Stockdataset(train_data, input_size=IN_DIM, day_interval=DAY_INT)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_dataset = Stockdataset(test_data, input_size=IN_DIM, day_interval=DAY_INT)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "print(next(iter(test_dataset[-1])).dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataloader = train_dataloader.type(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=32, out_features=32, bias=True)"
      ]
     },
     "execution_count": 663,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Linear(32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, emb_dim, num_heads, dropout=0.0, bias=False, encoder_decoder_attention=False, causal=False):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "        self.head_dim = emb_dim // num_heads\n",
    "        assert self.head_dim * num_heads == self.emb_dim, 'emb_dim must be divisible by num_heads'\n",
    "\n",
    "        self.encoder_decoder_attention = encoder_decoder_attention\n",
    "        self.causal = causal\n",
    "        self.q_proj = nn.Linear(emb_dim, emb_dim, bias=bias)\n",
    "        self.k_proj = nn.Linear(emb_dim, emb_dim, bias=bias)\n",
    "        self.v_proj = nn.Linear(emb_dim, emb_dim, bias=bias)\n",
    "        self.out_proj = nn.Linear(emb_dim, emb_dim, bias=bias)\n",
    "        # print(self.q_proj.grad)\n",
    "    \n",
    "    def transpose_for_scores(self, x):\n",
    "        \"\"\"\n",
    "        To-Do : Reshape input\n",
    "          Args : batch_size X sequence_length X embedding dimension\n",
    "          Return : batch_size X # attention head X sequence_length X head dimension\n",
    "        \"\"\"\n",
    "        new_x_hape = x.size()[:-1] + (\n",
    "            self.num_heads,\n",
    "            self.head_dim\n",
    "        )\n",
    "        x = x.view(*new_x_hape)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "    \n",
    "    def scaled_dot_product(self, query: torch.Tensor, key: torch.Tensor, value: torch.Tensor, attention_mask: torch.BoolTensor):\n",
    "        \"\"\"\n",
    "        To-Do : Implement scaled dot product\n",
    "          Args:\n",
    "            Query (Tensor): shape `(batch, seq_len, emb_dim)`\n",
    "            Key (Tensor): shape `(batch, seq_len, emb_dim)`\n",
    "            Value (Tensor): shape `(batch, seq_len, emb_dim)`\n",
    "            attention_mask: binary BoolTensor of shape `(batch, seq_len)` or `(seq_len, seq_len)`\n",
    "\n",
    "          Returns:\n",
    "            attn_output : attended output (result of attention mechanism)\n",
    "            attn_weights: value of each attention\n",
    "        \"\"\"\n",
    "        attn_weights = torch.matmul(query, key.transpose(-1, -2)) / math.sqrt(self.emb_dim)\n",
    "        if attention_mask is not None:\n",
    "            attn_weights = attn_weights.maked_fill(attention_mask.unsqueeze(1), float('-inf'))\n",
    "        \n",
    "        attn_weights = F.softmax(attn_weights, dim=-1)\n",
    "        attn_probs = F.dropout(attn_weights, p=self.dropout, training=self.training)\n",
    "        attn_output = torch.matmul(attn_probs, value)\n",
    "\n",
    "        return attn_output, attn_probs\n",
    "    \n",
    "    def MultiHead_scaled_dot_product(self, query: torch.Tensor, key: torch.Tensor, value: torch.Tensor, attention_mask: torch.BoolTensor):\n",
    "        \"\"\"\n",
    "        To-Do : Implement Multi-head version of scaled dot product, please also take the causal masking into account.\n",
    "          Args:\n",
    "            Query (Tensor): shape `(batch,# attention head, seq_len, head_dim)`\n",
    "            Key (Tensor): shape `(batch,# attention head, seq_len, head_dim)`\n",
    "            Value (Tensor): shape `(batch,# attention head, seq_len, head_dim)`\n",
    "            attention_mask: binary BoolTensor of shape `(batch, src_len)` or `(seq_len, seq_len)`\n",
    "\n",
    "          Returns:\n",
    "            attn_output : attended output (result of attention mechanism)\n",
    "            attn_weights: value of each attention\n",
    "        \"\"\"\n",
    "        attn_weights = torch.matmul(query, key.transpose(-1, -2)) / math.sqrt(self.head_dim)\n",
    "\n",
    "        if attention_mask is not None:\n",
    "            if self.causal:\n",
    "                #(seq_len x seq_len)\n",
    "                attn_weights = attn_weights.masked_fill(attention_mask.unsqueeze(0).unsqueeze(1), float('-inf'))\n",
    "            else:\n",
    "                #(batch_size x seq_len)\n",
    "                attn_weights = attn_weights.masked_fill(attention_mask.unsqueeze(1).unsqueeze(2), float('-inf'))\n",
    "        \n",
    "        attn_weights = F.softmax(attn_weights, dim=-1)\n",
    "        attn_probs = F.dropout(attn_weights, p=self.dropout, training=self.training)\n",
    "\n",
    "        attn_output = torch.matmul(attn_probs, value)\n",
    "        attn_output = attn_output.permute(0, 2, 1, 3).contiguous()\n",
    "        concat_attn_output_shape = attn_output.size()[:-2] + (self.emb_dim,) # batch_size, seq_len, emb_dim\n",
    "        attn_output = attn_output.view(*concat_attn_output_shape)\n",
    "        attn_output = self.out_proj(attn_output)\n",
    "\n",
    "        return attn_output, attn_weights\n",
    "    \n",
    "    def forward(self, query: torch.Tensor, key: torch.Tensor, attention_mask: torch.Tensor = None):\n",
    "        query = query.type('torch.FloatTensor').to('cuda')\n",
    "        print('-------------')\n",
    "        print(query[-1])\n",
    "        q = self.q_proj(query)\n",
    "\n",
    "        if self.encoder_decoder_attention:\n",
    "            k = self.k_proj(key)\n",
    "            v = self.v_proj(key)\n",
    "        else: # self attention\n",
    "            k = self.k_proj(query)\n",
    "            v = self.v_proj(query)\n",
    "        \n",
    "        q = self.transpose_for_scores(q)\n",
    "        k = self.transpose_for_scores(k)\n",
    "        v = self.transpose_for_scores(v)\n",
    "\n",
    "        attn_output, attn_weights = self.MultiHead_scaled_dot_product(q, k, v, attention_mask)\n",
    "        return attn_output, attn_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, emb_dim: int, d_ff: int, droptout: float = 0.1):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        self.w_1 = nn.Linear(emb_dim, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, emb_dim)\n",
    "        self.dropout = droptout\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.activation(self.w_1(x))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        x = self.w_2(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        return x + residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalPositionalEmbedding(nn.Embedding):\n",
    "    def __init__(self, num_positions, embedding_dim, padding_idx=None):\n",
    "        super().__init__(num_positions, embedding_dim)\n",
    "        self.weight = self._init_weight(self.weight)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _init_weight(out: nn.Parameter):\n",
    "        n_pos, embed_dim = out.shape\n",
    "        pe = nn.Parameter(torch.zeros(out.shape))\n",
    "        for pos in range(n_pos):\n",
    "            for i in range(0, embed_dim, 2):\n",
    "                pe[pos, i].data.copy_(torch.tensor(np.sin(pos / (10000**(i/embed_dim)))))\n",
    "                pe[pos, i+1].data.copy_(torch.tensor(np.cos(pos/(10000**(i+1)/embed_dim))))\n",
    "        pe.detach_()\n",
    "        return pe\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def forward(self, input_ids):\n",
    "        bsz, seq_len =input_ids.shape[:2]\n",
    "        positions = torch.arange(seq_len, dtype=torch.long, device=self.weight.device)\n",
    "        return super().forward(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.emb_dim = config.emb_dim\n",
    "        self.ffn_dim = config.ffn_dim\n",
    "        self.self_attn = MultiHeadAttention(\n",
    "            emb_dim=self.emb_dim,\n",
    "            num_heads=config.attention_heads,\n",
    "            dropout=config.attention_dropout)\n",
    "        self.self_att_layer_norm = nn.LayerNorm(self.emb_dim)\n",
    "        self.dropout = config.dropout\n",
    "        self.activation_fn = nn.ReLU()\n",
    "        self.PositionWiseFeedForward = PositionWiseFeedForward(self.emb_dim, self.ffn_dim, self.dropout)\n",
    "        self.final_layer_norm = nn.LayerNorm(self.emb_dim)\n",
    "    \n",
    "    def forward(self, x, encoder_padding_mask):\n",
    "        \"\"\"\n",
    "        To-Do : Implement transformer encoder layer\n",
    "          Args:\n",
    "            x (Tensor): input to the layer of shape `(batch, seq_len, emb_dim)`\n",
    "            encoder_padding_mask: binary BoolTensor of shape `(batch, src_len)`\n",
    "\n",
    "          Returns:\n",
    "            x : encoded output of shape `(batch, seq_len, emb_dim)`\n",
    "            self_attn_weights: self attention score\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        x, attn_weights = self.self_attn(query=x, key=x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = residual + x\n",
    "        x = x.type('torch.DoubleTensor').to('cuda')\n",
    "        x = self.self_att_layer_norm(x)\n",
    "        x = self.PositionWiseFeedForward(x)\n",
    "        x = self.final_layer_norm(x)\n",
    "        if torch.isinf(x).any() or torch.isnan(x).any():\n",
    "          clamp_value = torch.finfo(x.type).max - 1000\n",
    "          x = torch.clamp(x, min=-clamp_value, max=clamp_value)\n",
    "        return x, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dropout = config.dropout\n",
    "        self.max_source_positions = config.max_position_embeddings\n",
    "        \n",
    "        self.embed_positions = SinusoidalPositionalEmbedding(\n",
    "            config.max_position_embeddings, config.emb_dim)\n",
    "        self.layers = nn.ModuleList([EncoderLayer(config) for _ in range(config.encoder_layers)])\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        \"\"\"\n",
    "        To-Do : Implement the transformer encoder\n",
    "          Args:\n",
    "            input_ids (Tensor): input to the layer of shape `(batch, seq_len)`\n",
    "            attention_mask: binary BoolTensor of shape `(batch, src_len)`\n",
    "\n",
    "          Returns:\n",
    "            x: encoded output of shape `(batch, seq_len, emb_dim)`\n",
    "            self_attn_scores: a list of self attention score of each layer\n",
    "        \"\"\"\n",
    "        embed_pos = self.embed_positions(input_ids)\n",
    "        # print(embed_pos)\n",
    "        x = input_ids + embed_pos\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        self_attn_scores = []\n",
    "        for encoder_layer in self.layers:\n",
    "            x, attn = encoder_layer(x, attention_mask)\n",
    "            self_attn_scores.append(attn.detach())\n",
    "            \n",
    "        return x, self_attn_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        # self.SRC_vocab = SRC_vocab\n",
    "        # self.TRG_vocab = TRG_vocab\n",
    "\n",
    "        # self.enc_embedding = nn.Embedding(len(SRC_vocab.itos), config.emb_dim, padding_idx=SRC_vocab.stoi['<pad>'])\n",
    "        # self.dec_embedding = nn.Embedding(len(TRG_vocab.itos), config.emb_dim, padding_idx=TRG_vocab.stoi['<pad>'])\n",
    "\n",
    "        self.encoder = Encoder(config)\n",
    "        # self.decoder = Decoder(config, self.dec_embedding)\n",
    "\n",
    "        self.prediction_head = nn.Linear(config.emb_dim, 1)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    # def generate_mask(self, src, trg):\n",
    "    #     # Mask encoder attention to ignore padding\n",
    "    #     enc_attention_mask = src.eq(self.SRC_vocab.stoi['<pad>']).to(device)\n",
    "    #     # Mask decoder attention for causality\n",
    "    #     tmp = torch.ones(trg.size(1), trg.size(1), dtype=torch.bool, device=device)\n",
    "    #     mask = torch.arange(tmp.size(-1), device=device)\n",
    "    #     dec_attention_mask = tmp.masked_fill_(mask < (mask + 1).view(tmp.size(-1), 1), False).to(device)\n",
    "\n",
    "    #     return enc_attention_mask, dec_attention_mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                if 'weight' in name:\n",
    "                    nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "                else:\n",
    "                    nn.init.constant_(param.data, 0)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # enc_attention_mask, dec_causal_mask = self.generate_mask(src, trg)\n",
    "        encoder_output, encoder_attention_scores = self.encoder(\n",
    "            input_ids=src,\n",
    "            attention_mask=None\n",
    "            # attention_mask=enc_attention_mask\n",
    "        )\n",
    "\n",
    "        # decoder_output, decoder_attention_scores = self.decoder(\n",
    "        #     trg,\n",
    "        #     encoder_output,\n",
    "        #     encoder_attention_mask=enc_attention_mask,\n",
    "        #     decoder_causal_mask=dec_causal_mask,\n",
    "        # )\n",
    "        # decoder_output = self.prediction_head(decoder_output)\n",
    "        encoder_output = self.prediction_head(encoder_output)\n",
    "\n",
    "        return encoder_output, encoder_attention_scores\n",
    "        # return decoder_output, encoder_attention_scores, decoder_attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Create the configuration for the transformer model\n",
    "config = easydict.EasyDict({\n",
    "    \"emb_dim\": IN_DIM,\n",
    "    \"ffn_dim\": 256,\n",
    "    \"attention_heads\": 4,\n",
    "    \"attention_dropout\": 0.0,\n",
    "    \"dropout\": 0.2,\n",
    "    \"max_position_embeddings\": BATCH_SIZE,\n",
    "    \"encoder_layers\": 3,\n",
    "    \"decoder_layers\": 3,\n",
    "})\n",
    "\n",
    "# Constants for training\n",
    "N_EPOCHS = 100\n",
    "learning_rate = 5e-4\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# Instantiate the model using the new Vocab instances instead of the Fields\n",
    "model = TransformerEncoder(config)\n",
    "model.to(device)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define the loss function, ignoring the index of the padding token\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "tensor([[0.1595, 0.0000, 0.1374, 1.3895, 0.1476, 1.4013, 0.1440, 1.3968, 0.1380,\n",
      "         1.3782, 0.1357, 1.3918, 0.1482, 1.3953, 0.1573, 1.4075, 0.1610, 1.4099,\n",
      "         0.1663, 1.4091, 0.1665, 1.4118, 0.1635, 0.0000, 0.1753, 0.0000, 0.1716,\n",
      "         0.0000, 0.1846, 1.4250, 0.1644, 0.0000, 0.1774, 1.4250, 0.1774, 1.4319,\n",
      "         0.1676, 1.4209, 0.0000, 1.4245, 0.0000, 1.4200, 0.1637, 0.0000, 0.1567,\n",
      "         1.4052, 0.1472, 1.3972, 0.1463, 1.4066, 0.1574, 0.0000, 0.1723, 1.4223,\n",
      "         0.1761, 1.4266, 0.1773, 1.4192, 0.1756, 1.4199, 0.1666, 1.4124, 0.1636,\n",
      "         1.4148],\n",
      "        [1.5174, 1.7130, 1.3582, 1.7784, 1.1683, 1.7866, 1.0225, 1.7849, 0.9187,\n",
      "         1.7993, 0.8423, 0.0000, 0.7655, 1.7858, 0.6721, 1.7689, 0.6453, 0.0000,\n",
      "         0.5875, 1.7376, 0.5517, 1.7261, 0.5035, 1.7075, 0.0000, 1.6993, 0.4758,\n",
      "         1.6955, 0.4232, 1.6467, 0.4369, 1.6827, 0.4472, 1.6832, 0.4105, 1.6681,\n",
      "         0.0000, 1.6823, 0.4500, 1.6849, 0.4399, 0.0000, 0.4636, 0.0000, 0.4599,\n",
      "         1.7238, 0.4729, 1.7482, 0.4916, 1.7409, 0.4415, 0.0000, 0.0000, 0.0000,\n",
      "         0.4349, 0.0000, 0.4391, 1.6889, 0.4467, 1.7227, 0.4526, 1.7550, 0.4931,\n",
      "         1.7397],\n",
      "        [0.0000, 2.3165, 2.2640, 2.1914, 2.0355, 0.0000, 0.0000, 2.1750, 1.6675,\n",
      "         2.2051, 1.4952, 2.1934, 1.3873, 2.1891, 1.2947, 2.2079, 1.2223, 2.2136,\n",
      "         0.0000, 2.2197, 1.0922, 2.1977, 1.0276, 2.1896, 1.0308, 2.2377, 0.0000,\n",
      "         2.2728, 1.0668, 2.2560, 1.0295, 2.2593, 1.0608, 2.2792, 1.0740, 2.3113,\n",
      "         1.0698, 2.2819, 1.0637, 0.0000, 0.0000, 0.0000, 1.0086, 2.2564, 0.9762,\n",
      "         2.2396, 0.9881, 2.2347, 0.9796, 2.2460, 0.9998, 2.2719, 1.0157, 2.2730,\n",
      "         1.0119, 2.2588, 0.0000, 2.2453, 0.9981, 2.2113, 0.9585, 2.1517, 0.8948,\n",
      "         2.1601],\n",
      "        [0.7171, 1.7983, 1.4954, 1.7227, 1.6927, 1.7412, 1.6772, 0.0000, 1.5235,\n",
      "         0.0000, 1.3238, 1.7078, 1.1146, 1.7529, 0.9929, 1.7699, 0.8963, 1.7835,\n",
      "         0.8183, 1.8038, 0.7510, 1.7994, 0.6825, 1.7909, 0.6883, 1.8152, 0.6568,\n",
      "         1.8313, 0.6516, 1.8250, 0.6253, 0.0000, 0.5936, 0.0000, 0.6080, 1.8222,\n",
      "         0.5954, 1.7787, 0.5688, 1.8220, 0.5758, 0.0000, 0.5683, 1.7913, 0.5387,\n",
      "         1.7850, 0.0000, 1.7699, 0.5147, 1.7797, 0.5525, 1.7953, 0.5806, 1.8284,\n",
      "         0.5833, 1.8220, 0.5812, 1.8267, 0.5593, 1.8205, 0.5540, 1.8002, 0.0000,\n",
      "         0.0000]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Double but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[671], line 50\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(\u001b[38;5;28mrange\u001b[39m(N_EPOCHS), total\u001b[38;5;241m=\u001b[39mN_EPOCHS):\n\u001b[1;32m---> 50\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mTrain Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Train PPL: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmath\u001b[38;5;241m.\u001b[39mexp(train_loss)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m7.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Evaluation on test set\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[671], line 15\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[0;32m     11\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     13\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 15\u001b[0m output, enc_attention_scores, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, labels)\n\u001b[0;32m     18\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\alan.kwak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alan.kwak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[669], line 38\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[1;34m(self, src)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, src):\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;66;03m# enc_attention_mask, dec_causal_mask = self.generate_mask(src, trg)\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m     encoder_output, encoder_attention_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[0;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# attention_mask=enc_attention_mask\u001b[39;49;00m\n\u001b[0;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;66;03m# decoder_output, decoder_attention_scores = self.decoder(\u001b[39;00m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;66;03m#     trg,\u001b[39;00m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;66;03m#     encoder_output,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# decoder_output = self.prediction_head(decoder_output)\u001b[39;00m\n\u001b[0;32m     51\u001b[0m     encoder_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_head(encoder_output)\n",
      "File \u001b[1;32mc:\\Users\\alan.kwak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alan.kwak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[668], line 30\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[1;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[0;32m     28\u001b[0m self_attn_scores \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m encoder_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 30\u001b[0m     x, attn \u001b[38;5;241m=\u001b[39m \u001b[43mencoder_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     self_attn_scores\u001b[38;5;241m.\u001b[39mappend(attn\u001b[38;5;241m.\u001b[39mdetach())\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x, self_attn_scores\n",
      "File \u001b[1;32mc:\\Users\\alan.kwak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alan.kwak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[667], line 32\u001b[0m, in \u001b[0;36mEncoderLayer.forward\u001b[1;34m(self, x, encoder_padding_mask)\u001b[0m\n\u001b[0;32m     30\u001b[0m x \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m x\n\u001b[0;32m     31\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch.DoubleTensor\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 32\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_att_layer_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mPositionWiseFeedForward(x)\n\u001b[0;32m     34\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_layer_norm(x)\n",
      "File \u001b[1;32mc:\\Users\\alan.kwak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alan.kwak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alan.kwak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:201\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alan.kwak\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\functional.py:2546\u001b[0m, in \u001b[0;36mlayer_norm\u001b[1;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[0;32m   2542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[0;32m   2543\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m   2544\u001b[0m         layer_norm, (\u001b[38;5;28minput\u001b[39m, weight, bias), \u001b[38;5;28minput\u001b[39m, normalized_shape, weight\u001b[38;5;241m=\u001b[39mweight, bias\u001b[38;5;241m=\u001b[39mbias, eps\u001b[38;5;241m=\u001b[39meps\n\u001b[0;32m   2545\u001b[0m     )\n\u001b[1;32m-> 2546\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: expected scalar type Double but found Float"
     ]
    }
   ],
   "source": [
    "def train(model: nn.Module,\n",
    "          iterator: DataLoader,\n",
    "          optimizer: optim.Optimizer,\n",
    "          criterion: nn.Module):\n",
    "\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for inputs, labels in iterator:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output, enc_attention_scores, _ = model(inputs)\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "\n",
    "def evaluate(model: nn.Module,\n",
    "             iterator: DataLoader,\n",
    "             criterion: nn.Module):\n",
    "\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in iterator:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Assuming src and trg are already tensorized and padded\n",
    "            # If not, you should perform those steps here\n",
    "\n",
    "            output, attention_score, _ = model(inputs)\n",
    "\n",
    "            loss = criterion(output, labels)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "# Training loop\n",
    "for epoch in tqdm.tqdm(range(N_EPOCHS), total=N_EPOCHS):\n",
    "    train_loss = train(model, train_dataloader, optimizer, criterion)\n",
    "\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "\n",
    "# Evaluation on test set\n",
    "test_loss = evaluate(model, test_dataloader, criterion)\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
